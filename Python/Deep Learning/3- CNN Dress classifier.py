# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kFeuJDzs4hEeJHVPukfqby9r-JA1WMJ1
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

#Loading Dataset
Data_loader = tf.keras.datasets.fashion_mnist
(x_train, y_train) , (x_test, y_test) =  Data_loader.load_data()

class_labels = ['T-shirt','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle Boot']

# Create an MLP
#NN = Sequential([
#                 Dense(64, activation='relu',input_shape=(784,)),
#                 Dense(10, activation='softmax')
#])

#equivalent to above code
MLP = Sequential()
MLP.add(tf.keras.layers.Flatten(input_shape=(28,28))) 
MLP.add(tf.keras.layers.Dense(64, activation='relu'))
MLP.add(tf.keras.layers.Dense(10, activation='softmax'))
#---------------------------
MLP.weights
MLP.summary()

#Create Compile 
MLP.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9)
            ,loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)
            ,metrics=[tf.keras.metrics.Accuracy(),tf.keras.metrics.MeanAbsoluteError()] )

# Batch Size & Epochs
#Stochastic gradient descent is an iterative learning algorithm that
#uses a training dataset to update a model.
#Batch Size:
#The Batch Size is a hyperparameter of gradient descent that controls 
#the number of training samples to work through before the modelâ€™s internal parameters are updated.
#Epochs:
#The number of Epochs is a hyperparameter of gradient descent that 
#controls the number of complete passes through the training dataset.

#Create an Convolutional Neural Network
CNN = tf.keras.models.Sequential()
CNN.add(tf.keras.layers.Conv2D(filters= 16,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)))
CNN.add(tf.keras.layers.MaxPool2D(pool_size=(3,3)))
CNN.add(tf.keras.layers.Flatten())
CNN.add(tf.keras.layers.Dense(10,activation='softmax'))

CNN.summary()

#Create Compile
#The error arose because 'categorical_crossentropy' works on one-hot encoded target
#, while 'sparse_categorical_crossentropy' works on integer target.

#CNN.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
CNN.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)
            ,loss =tf.keras.losses.SparseCategoricalCrossentropy()
            ,metrics=[tf.keras.metrics.SparseCategoricalAccuracy(), tf.keras.metrics.MeanAbsoluteError()])

x_train = x_train/255
x_test = x_test/255

#Train the Neural Network / Fit function
history = CNN.fit(x_train, y_train, epochs=2, batch_size=256)

df = pd.DataFrame(history.history)
print(df.head)
plt.plot(df.sparse_categorical_accuracy)
#plt.figure(1)
#plt.plot(df.loss)

CNN.evaluate(x_test,y_test,verbose=1)

image_no = np.random.choice(x_test.shape[0])
test_sample = x_test[image_no]
plt.imshow(test_sample)
pred = CNN.predict(test_sample[np.newaxis,...,np.newaxis])
class_labels[np.argmax(pred)]